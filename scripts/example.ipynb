{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import automatic_speech_recognition as asr\n",
    "# %load_ext autoreload\n",
    "# %autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = '/blue/vbindschadler/hadi10102/train_data/speech_commands/'\n",
    "\n",
    "file_paths = asr.util.preprocess.read_simple_word(data_dir)\n",
    "\n",
    "# Split data into train, val, and test\n",
    "train_files_paths = file_paths[:6400]\n",
    "val_files_paths = file_paths[6400: 6400 + 800]\n",
    "test_files_paths = file_paths[-800:]\n",
    "\n",
    "# Reads the audio data for the file_paths\n",
    "train_ds = asr.util.preprocess.preprocess_simple_word(train_files_paths)\n",
    "val_ds = asr.util.preprocess.preprocess_simple_word(val_files_paths)\n",
    "test_ds = asr.util.preprocess.preprocess_simple_word(test_files_paths)\n",
    "\n",
    "# Padd the data sets\n",
    "train_ds_padded = train_ds.padded_batch(8, padded_shapes={'audio_input': (None, 1), \n",
    "                                                          'y_true' : (None,),\n",
    "                                                          'y_true_length' :()})\n",
    "\n",
    "val_ds_padded = val_ds.padded_batch(8, padded_shapes={'audio_input': (None, 1),\n",
    "                                                      'y_true' : (None,),\n",
    "                                                      'y_true_length' :()})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Model Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Output logits missing from loss dictionary. We assume this was done on purpose. The fit and evaluate APIs will not be expecting any data to be passed to logits.\n"
     ]
    }
   ],
   "source": [
    "# Load the model input and output layers\n",
    "logits, input_audio, y_true, y_true_length = asr.models.cnn_raw_speech.cnn_raw_speech.get_model()\n",
    "\n",
    "# Setup the CTC loss layer\n",
    "ctc_loss_layer = asr.util.ctc_loss.get_ctc_layer(logits, y_true, y_true_length)\n",
    "\n",
    "# Setup Model and training params\n",
    "model = tf.keras.Model(inputs = [input_audio, y_true, y_true_length], outputs = [ctc_loss_layer, logits])\n",
    "opt = tf.keras.optimizers.Adam(learning_rate=0.0001)\n",
    "\n",
    "model.compile(loss={'ctc': lambda y_true, y_pred: y_pred}, optimizer = opt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint = ModelCheckpoint(\"best_model.hdf5\", monitor='loss', verbose=1, save_best_only=True, mode='auto', period=1)\n",
    "early_stop = EarlyStopping(monitor='val_loss', min_delta=0.0001, patience=10, verbose=1, mode='min')\n",
    "\n",
    "model.fit(x = train_ds_padded, \n",
    "          validation_data = val_ds_padded, \n",
    "          shuffle = True,\n",
    "          callbacks = [checkpoint, early_stop],\n",
    "          epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'ctc/ExpandDims_1:0' shape=(?, 1) dtype=float32>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "deepspeech_kernel",
   "language": "python",
   "name": "deepspeech_kernel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
